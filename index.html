<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Morpheus: Neural-driven Animatronic Face</title>
  <!-- Bootstrap -->
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
  <style>
    body {
      background: rgb(255, 255, 255) no-repeat fixed top left;
      font-family: 'Open Sans', sans-serif;
    }
  </style>

</head>

<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container-fluid">
      <div class="row">
        <div class="col">
          <h2 style="font-size:30px;">Morpheus: Neural-driven Animatronic Face</h2>
          <h4 style="color:#6e6e6e;"> RSS 2025 </h4>
          <hr>
          <h6>
            <a target="_blank">Zongzheng Zhang<sup>*</sup></a><sup>1,2</sup>,</span>&nbsp; &nbsp;
            <a target="_blank">Jiawen Yang<sup>*</sup></a><sup>1</sup>,</span>&nbsp; &nbsp;
            <a target="_blank">Ziqiao Peng<sup>1</sup></a>,</span>&nbsp; &nbsp;
            <a target="_blank">Meng Yang<sup>4</sup></a>,</span>&nbsp; &nbsp;
            <br>
            <a href="https://majianzhu.com/" target="_blank">Jianzhu Ma<sup>1</sup></a>,</span>&nbsp; &nbsp;
            <a target="_blank">Lin Cheng<sup>5</sup></a>,</span>&nbsp; &nbsp;
            <a href="http://hxu.rocks/" target="_blank">Huazhe Xu<sup>3</sup>&nbsp;</a>and</span>&nbsp; &nbsp;
            <a href="https://hangzhaomit.github.io/" target="_blank">Hang Zhao<sup>3</sup></a>
            <a href="https://sites.google.com/view/fromandto/" target="_blank">Hao Zhao<sup>&dagger;</sup><sup>1,2</sup></a>

            <br>
            <br>
            <p> <sup>1</sup>Institute for AI Industry Research (AIR), Tsinghua University,&nbsp; &nbsp;
              <sup>2</sup>Beijing Academy of Artificial Intelligence (BAAI),&nbsp; &nbsp;
              <sup>3</sup>Institute for Interdisciplinary Information Sciences(IIIS), Tsinghua University,&nbsp; &nbsp;
              <sup>4</sup>MGI Tech, Shenzhen, China,
              <sup>5</sup>Beihang University
              <br>
            </p>
            <p> <sup>*</sup> equal contributions &nbsp;
              <sup>†</sup> corresponding author &nbsp;
              <br>
            </p>

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://roboticsconference.org/program/papers/80/" role="button" target="_blank">
                    <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/JYChen18/Dexonomy" role="button" target="_blank">
                <i class="fa fa-github-alt"></i> Hardware </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://huggingface.co/datasets/JiayiChenPKU/Dexonomy/tree/main" role="button" target="_blank">
                <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/JYChen18/DexLearn" role="button" target="_blank">
                <i class="fa fa-github-alt"></i> Dataset </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://gfrl.github.io/DexAnno/" role="button" target="_blank">
                <i class="fa fa-github-alt"></i> Demo </a> </p>
              </div>
            </div>

        </div>
      </div>
    </div>
  </div>
</section>

<div class="youtube-container">
  <iframe 
    src="https://www.youtube.com/embed/5sUwuC3lW5U?si=3C5MhM_9bUFpEzcn" 
    frameborder="0"
    allowfullscreen
    style="width: 100%; height: 100%; display: block; margin: 0 auto;">
  </iframe>
</div>


<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12 text-center">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="Fig/teaser.jpg" alt="input" class="img-responsive" width="100%" />
          <br>
        </div>
        <!-- </div> -->
      </div>
    </div>
  </div>
</section>
<br>

<!-- abstract -->
<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <h2><strong>Abstract</strong></h2>
        <hr style="margin-top:0px">
        <p class="text-justify">
          Previous animatronic faces struggle to express emotions effectively due to hardware and software limitations. On the hardware side, earlier approaches either use rigid-driven mechanisms, which provide precise control but are difficult to design within constrained spaces, or tendon-driven mechanisms, which are more space-efficient but challenging to control. In contrast, we propose a hybrid actuation approach that combines the best of both worlds. The eyes and mouth—key areas for emotional expression—are controlled using rigid mechanisms for precise movement, while the nose and cheek, which convey subtle facial microexpressions, are driven by strings. This design allows us to build a compact yet versatile hardware platform capable of expressing a wide range of emotions. On the algorithmic side, our method introduces a self-modeling network that maps motor actions to facial landmarks, allowing us to automatically establish the relationship between blendshape coefficients for different facial expressions and the corresponding motor control signals through gradient backpropagation. We then train a neural network to map speech input to corresponding blendshape controls. With our method, we can generate distinct emotional expressions such as happiness, fear, disgust, and anger, from any given sentence, each with nuanced, emotion specific control signals—a feature that has not been demonstrated in earlier systems. We release the hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware and https://github.com/ZZongzheng0918/Morpheus-Software.

        </p>
      </div>
    </div>
  </div>
</section>
<br>

<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <h2><strong>Speech-driven Expression Results</strong></h2>
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/1-sky.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/2-store.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/3-worklate.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/h4-keys.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/5-weather.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>


<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/6-eat.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>


<section>
  <div class="container" style="width:58%">
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <video width="90%" playsinline="" preload="" muted="" controls>
            <source src="video/7-food.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>


<!-- citing -->
<div class="container" style="width:58%">
  <div class="row ">
    <div class="col-12">
      <h2><strong>Citation</strong></h2>
      <hr style="margin-top:0px">
      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>
        @article{Morpheus,
          title={Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control},
          author={Zongzheng Zhang and Jiawen Yang and Ziqiao Peng and Meng Yang and Jianzhu Ma and Lin Cheng and Huazhe Xu and Hang Zhao and Hao Zhao},
          journal={Robotics: Science and Systems (RSS)},
          year={2025}
        }
</code></pre>
    </div>
  </div>
</div>
<br>
<br>

<!-- Contact -->
<div class="container" style="width:58%">
  <div class="row ">
    <div class="col-12">
      <h2><strong>Contact</strong></h2>
      <hr style="margin-top:0px">
      <p>If you have any questions, please feel free to contact <b>Hao Zhang</b> at zhaohao@air.tsinghua.edu.cn.
      </p>
      </pre>
    </div>
  </div>
</div>



<footer class="text-center" style="margin-bottom:10px; font-size: medium;">
  <hr>
  Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the <a
    href="https://lioryariv.github.io/idr/" target="_blank">website template</a>.
</footer>
<script>
  MathJax = {
    tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>

</html>